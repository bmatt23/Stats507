{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# importing the necessary libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#reading in the NHANES data via the internet and adding column for cohort\n",
    "year11 = pd.read_sas('https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT')\n",
    "year11.insert(0,\"Cohort\",11)\n",
    "year13 = pd.read_sas('https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT')\n",
    "year13.insert(0,\"Cohort\",13)\n",
    "year15 = pd.read_sas('https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT')\n",
    "year15.insert(0,\"Cohort\",15)\n",
    "year17 = pd.read_sas('https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT')\n",
    "year17.insert(0,\"Cohort\",17)\n",
    "sets = [year11, year13, year15, year17]\n",
    "\n",
    "#creating a dataframe and filterng out for just the data we want\n",
    "data = pd.concat(sets)\n",
    "labels = ['Cohort','SEQN','RIDAGEYR','RIDRETH3','DMDEDUC2','DMDMARTL',\n",
    "         'RIDSTATR','SDMVPSU','SDMVSTRA','WTMEC2YR','WTINT2YR','RIAGENDR']\n",
    "data = data[labels]\n",
    "\n",
    "#renaming columns\n",
    "new_cols=[\n",
    "    'cohort','unique_id',\n",
    "    'age','race_ethnicity',\n",
    "    'education','marital_status',\n",
    "    'status','psuedo_PSU',\n",
    "    'psuedo_stratum','exam_weight',\n",
    "    'interview_weight', 'gender'\n",
    "]\n",
    "\n",
    "new_names_map = {data.columns[i]:new_cols[i] for i in range(len(new_cols))}\n",
    "\n",
    "data.rename(new_names_map, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# for the categorical data, specifying what each category represents\n",
    "data['race_ethnicity'] = pd.Categorical(data['race_ethnicity'].replace(\n",
    "        {\n",
    "            1: 'Mexican American',\n",
    "            2: 'Other Hispanic',\n",
    "            3: 'Non-Hispanic White',\n",
    "            4: 'Non-Hispanic Black',\n",
    "            6: 'Non-Hispanic Asian',\n",
    "            7: 'Other Race - Including Multi-Racial',\n",
    "            np.nan: 'Missing'\n",
    "        }))\n",
    "\n",
    "data['education'] = pd.Categorical(data['education'].replace(\n",
    "        {\n",
    "            1: 'Less than 9th grade',\n",
    "            2: '9-11th grade (Includes 12th grade with no diploma)',\n",
    "            3: 'High school graduate/GED or equivalent',\n",
    "            4: 'Some college or AA degree',\n",
    "            5: 'College graduate or above',\n",
    "            7: 'Refused',\n",
    "            9: \"Don't know\",\n",
    "            np.nan : 'Missing'\n",
    "            \n",
    "        }))\n",
    "\n",
    "\n",
    "data['marital_status'] = pd.Categorical(data['marital_status'].replace(\n",
    "        {\n",
    "            1: 'Married',\n",
    "            2: 'Widowed',\n",
    "            3: 'Divorced',\n",
    "            4: 'Separated',\n",
    "            5: 'Never Married',\n",
    "            6: 'Living with partner',\n",
    "            77: 'Refused',\n",
    "            99: \"Don't know\",\n",
    "            np.nan : 'Missing'\n",
    "            \n",
    "        }))\n",
    "\n",
    "data['status'] = pd.Categorical(data['status'].replace(\n",
    "        {\n",
    "            1: 'Interviewed only',\n",
    "            2: 'Both interviewed and MEC examined',\n",
    "            np.nan : 'Missing'\n",
    "            \n",
    "        }))\n",
    "\n",
    "data['gender'] = pd.Categorical(data['gender'].replace(\n",
    "        {\n",
    "            1: 'Male',\n",
    "            2: 'Female',\n",
    "            np.nan : 'Missing'\n",
    "            \n",
    "        }))\n",
    "\n",
    "\n",
    "#using pickle to dump the dataframe we just created into the working directory.\n",
    "filepath = os.path.abspath('')\n",
    "pickle.dump(data,open(os.path.join(filepath,'demo_data'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "def dental(df = False):\n",
    "    \"\"\"\n",
    "Creates and filters/edits the dataframe for NHANES dental data from 2011-2017\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "df: False, the default argument, will just write the pickled file to the working\n",
    "directory. True will do the same thing but also return a dataframe.\n",
    "\n",
    " Returns\n",
    " -------\n",
    " Pickled df to working directory\n",
    " Cleaned up dataframe with labeled categoeries\n",
    " \"\"\"\n",
    "\n",
    "#scrape the data from the web for each year we need and insert cohort year    \n",
    "    year11 = pd.read_sas(\n",
    "        'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/OHXDEN_G.XPT'\n",
    "    )\n",
    "    year11.insert(0,\"cohort\",11)\n",
    "    year13 = pd.read_sas(\n",
    "        'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/OHXDEN_H.XPT'\n",
    "    )\n",
    "    year13.insert(0,\"cohort\",13)\n",
    "    year15 = pd.read_sas('https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/OHXDEN_I.XPT'\n",
    "                        )\n",
    "    year15.insert(0,\"cohort\",15)\n",
    "    year17 = pd.read_sas(\n",
    "        'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/OHXDEN_J.XPT'\n",
    "    )\n",
    "    year17.insert(0,\"cohort\",17)\n",
    "\n",
    "#combine the scrapes dfs\n",
    "    sets = [year11, year13, year15, year17]\n",
    "\n",
    "    data = pd.concat(sets)\n",
    "\n",
    "\n",
    "\n",
    "    labels = ['cohort','SEQN','OHDDESTS']\n",
    "# create lists of label names for each of the 32 teeth and category. \n",
    "    tooth_count = []\n",
    "    coronal_carries = []\n",
    "    for i in range(32):\n",
    "        if i<9:\n",
    "            coronal_carries.append('OHX0{0}CTC'.format(i+1))\n",
    "            tooth_count.append('OHX0{0}TC'.format(i+1))\n",
    "        else:\n",
    "            coronal_carries.append('OHX{0}CTC'.format(i+1))\n",
    "            tooth_count.append('OHX{0}TC'.format(i+1))\n",
    "            \n",
    "#website missing some variables, dropping four hypothetical categories\n",
    "    removelist = ['OHX01CTC','OHX16CTC', 'OHX17CTC', 'OHX32CTC']  \n",
    "\n",
    "\n",
    "\n",
    "    for i in removelist:\n",
    "        coronal_carries.remove(i)\n",
    "\n",
    "\n",
    "    labels += tooth_count\n",
    "    labels += coronal_carries\n",
    "\n",
    "\n",
    "    data = data[labels]\n",
    "\n",
    "# create categorical labels for each categorical variable\n",
    "\n",
    "    data['OHDDESTS'] = pd.Categorical(data['OHDDESTS'].replace(\n",
    "        {\n",
    "            1: 'complete', \n",
    "            2: 'partial',\n",
    "            3: 'not done'\n",
    "        }))\n",
    "\n",
    "\n",
    "    for i in tooth_count:\n",
    "        data[i] = pd.Categorical(data[i].replace(\n",
    "        {\n",
    "            1: 'Primary tooth (deciduous) present',\n",
    "            2: 'Permanent tooth present',\n",
    "            3: 'Dental implant',\n",
    "            4: 'Tooth not present',\n",
    "            5: 'Permanent dental root fragment present',\n",
    "            9: 'Could not assess'\n",
    "        }))\n",
    "\n",
    "    for j in coronal_carries:\n",
    "        data[j] = pd.Categorical(data[j].replace(\n",
    "        {\n",
    "            b'A': 'Primary tooth with a restored surface condition',\n",
    "            b'D': 'Sound primary tooth',\n",
    "            b'E': 'Missing due to dental disease',\n",
    "            b'F': 'Permanent tooth with a restored surface condition',\n",
    "            b'J': 'Permanent root tip is present but no restorative replacement is present',\n",
    "            b'K': 'Primary tooth with a dental carious surface condition',\n",
    "            b'M': 'Missing due to other causes',\n",
    "            b'P': 'Missing due to dental disease but replaced by a removable restoration',\n",
    "            b'Q': 'Missing due to other causes but replaced by a removable restoration',\n",
    "            b'R': 'Missing due to dental disease but replaced by a fixed restoration',\n",
    "            b'S': 'Sound permanent tooth',\n",
    "            b'T': 'Permanent root tip is present but a restorative replacement is present',\n",
    "            b'U': 'Unerupted',\n",
    "            b'X': 'Missing due to other causes but replaced by a fixed restoration',\n",
    "            b'Y': 'Tooth present, condition cannot be assessed',\n",
    "            b'Z': 'Permanent tooth with a dental carious surface condition'\n",
    "        }))\n",
    "        \n",
    "# dumping the df in the working directory for future use        \n",
    "    filepath = os.path.abspath('')\n",
    "    pickle.dump(data,open(os.path.join(filepath,'dental_data'),'wb'))\n",
    "\n",
    "#if the df is True, return the df we just created\n",
    "    if df == True:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo Data has 39156 cases.\n",
      "Dental Data has 35909 cases.\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "#Number of cases for the demo data\n",
    "#this is for part c.\n",
    "\n",
    "print('Demo Data has ' +str(data.shape[0]) + ' cases.')\n",
    "\n",
    "#Number of cases for the dental data\n",
    "dental1 = dental(True)\n",
    "print('Dental Data has ' + str(dental1.shape[0]) +' cases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
